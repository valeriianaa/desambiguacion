{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendiendo el algoritmo HMRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente nota es para comprender mejor el funcionamiento del algoritmo disponible en: https://github.com/wmkouw/infopriors-hPMRF/blob/master/hPottsMRF/hPottsMRF.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la función misma describe, inicializa las variables para una instancia de una clase hidden Potts-MRF, toma como parámetros:\n",
    "- el tamaño de la vecindad\n",
    "- el numero de iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init__(self, neighbourhood_size=(3, 3), num_iter=5):\n",
    "        \"\"\"\n",
    "        Initialize variables for an instance of a hidden Potts-MRF.\n",
    "        Parameters\n",
    "        ----------\n",
    "        neighbourhood_size : (int, int)\n",
    "            Size of the neighbourhood on which the variational approximation\n",
    "            depends (def: (1, 1))\n",
    "        num_iter : int\n",
    "            Number of iterations to run VB-EM.\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Store model parameters\n",
    "        if np.all(neighbourhood_size >= (3, 3)):\n",
    "            self.neighbourhood_size = neighbourhood_size\n",
    "        else:\n",
    "            raise ValueError('Neighbourhood size is too small')\n",
    "\n",
    "        # Optimization parameters\n",
    "        self.num_iter = num_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Hamiltonian(self, z):\n",
    "        r\"\"\"\n",
    "        Compute Hamiltonian function for Potts prior.\n",
    "        H(z) = \\prod_{n=1}^{N} \\prod_{n' \\in V(n)} \\delta(z_n == z_{n'}) .\n",
    "        where V(n) denotes the neighbourhood of the current pixel.\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : array(N x 1)\n",
    "            Label image.\n",
    "        Returns\n",
    "        -------\n",
    "        H : int\n",
    "            Value of H(z)\n",
    "        \"\"\"\n",
    "        # Count neighbourhood equality\n",
    "        H = 0\n",
    "\n",
    "        # Pad array with zeros\n",
    "        z = np.pad(z, [1, 1], mode='constant', constant_values=-1)\n",
    "\n",
    "        # Looping over every pixel\n",
    "        for i in range(1, z.shape[0]-1):\n",
    "            for j in range(1, z.shape[1]-1):\n",
    "\n",
    "                # Left neighbour\n",
    "                if z[i, j-1] == z[i, j]:\n",
    "                    H += 1\n",
    "\n",
    "                # Top neighbour\n",
    "                if z[i-1, j] == z[i, j]:\n",
    "                    H += 1\n",
    "\n",
    "                # Right neighbour\n",
    "                if z[i, j+1] == z[i, j]:\n",
    "                    H += 1\n",
    "\n",
    "                # Bottom neighbour\n",
    "                if z[i+1, j] == z[i, j]:\n",
    "                    H += 1\n",
    "\n",
    "        # Return counter\n",
    "        return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función mean_field_Potts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def mean_field_Potts(self, beta, Z):\n",
    "        \"\"\"\n",
    "        Mean-field variational approximation to Potts log-likelihood function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        beta : float\n",
    "            Smoothing parameter / granularity coefficient\n",
    "        Z : array (height x width x number of classes)\n",
    "            Label field to fit\n",
    "        Returns\n",
    "        -------\n",
    "        nlogq : float\n",
    "            Negative log-likelihood of current label field given current beta.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        H, W, K = Z.shape\n",
    "\n",
    "        # Test for one-hot in each page\n",
    "        for k in range(K):\n",
    "            if not np.all(np.unique(Z[:, :, k]) == [0, 1]):\n",
    "                raise ValueError(\"Label field is not binary in page \" + str(k))\n",
    "\n",
    "        # Pad shape with zero edge for easier neighbourhood extraction\n",
    "        Z = np.pad(Z, [1, 1], mode='constant', constant_values=0)\n",
    "\n",
    "        # Initialize negative log-likelihood\n",
    "        nll = 0\n",
    "        \n",
    "        # Loop over pixels\n",
    "        for h in range(1, H-1):\n",
    "            for w in range(1, W-1):\n",
    "\n",
    "                # Initialize intermediate terms\n",
    "                chi_ik = 0\n",
    "                ksi_ik = 0\n",
    "\n",
    "                # Select current class\n",
    "                for k in range(K):\n",
    "\n",
    "                    # Extract neighbourhood of current class\n",
    "                    delta_ik = Z[h-1:h+2, w-1:w+2, k]\n",
    "\n",
    "                    # First sum is neighbourhood comparison\n",
    "                    chi_ik += np.sum(Z[h, w, k] * delta_ik) - Z[h, w, k]**2\n",
    "\n",
    "                    # Second sum is purely over neighbourhood\n",
    "                    ksi_ik += np.exp(2*beta*(np.sum(delta_ik) - Z[h, w, k]))\n",
    "\n",
    "                # Update negative log-likelihood\n",
    "                nll += -2*beta*chi_ik + np.log(ksi_ik)\n",
    "\n",
    "        return nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función mean_field_Potts_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def mean_field_Potts_grad(self, beta, Z):\n",
    "        r\"\"\"\n",
    "        Partial derivative of mean-field Potts log-likelihood w.r.t. beta.\n",
    "        Derivative has the following form:\n",
    "        d/db log q(z|b) = \\sum_{i=1}^{n} 2 \\sum_{l=1}^{K} z_{il} \n",
    "            \\sum_{j \\in delta_i} \n",
    "        Parameters\n",
    "        ----------\n",
    "        beta : float\n",
    "            Smoothing parameter / granularity coefficient\n",
    "        Z : array (height by width by number of classes)\n",
    "            Label field to fit\n",
    "        Returns\n",
    "        -------\n",
    "        dB : float\n",
    "            Value of partial derivative for current beta.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        H, W, K = Z.shape\n",
    "\n",
    "        # Check for binary-class image\n",
    "        if K == 1:\n",
    "            Z = np.concatenate((Z, 1 - Z), axis=2)\n",
    "            K = 2\n",
    "\n",
    "        # Test for one-hot in each page\n",
    "        for k in range(K):\n",
    "            if not np.all(np.unique(Z[:, :, k]) == [0, 1]):\n",
    "                raise ValueError(\"Label field is not binary in page \" + str(k))\n",
    "\n",
    "        # Pad shape with zero edge for easier neighbourhood extraction\n",
    "        Z = np.pad(Z, [1, 1], mode='constant', constant_values=0)\n",
    "\n",
    "        # Initialize log-likelihood\n",
    "        dqdb = 0\n",
    "\n",
    "        # Loop over pixels\n",
    "        for h in range(1, H-1):\n",
    "            for w in range(1, W-1):\n",
    "\n",
    "                # Initialize intermediate terms\n",
    "                chi_ik = 0\n",
    "                ksi_ik = 0\n",
    "                tau_ik = 0\n",
    "\n",
    "                # Select current class\n",
    "                for k in range(K):\n",
    "\n",
    "                    # Extract neighbourhood of current class\n",
    "                    delta_ik = np.ravel(Z[h-1:h+2, w-1:w+2, k])\n",
    "\n",
    "                    # First sum is neighbourhood comparison\n",
    "                    chi_ik += 2*(np.sum(Z[h, w, k] * delta_ik) - Z[h, w, k]**2)\n",
    "\n",
    "                    # Second sum\n",
    "                    ksi_ik += 2*(np.sum(delta_ik) - Z[h, w, k])\n",
    "\n",
    "                    # Second sum is purely over neighbourhood\n",
    "                    tau_ik += np.exp(2*beta*(np.sum(delta_ik) - Z[h, w, k]))\n",
    "\n",
    "                # Update partial derivative\n",
    "                dqdb += -chi_ik + ksi_ik / tau_ik\n",
    "\n",
    "        return dqdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función maximum_likelihood_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maximum_likelihood_beta(self, Z, lb=[(0, None)], verbose=False):\n",
    "        \"\"\"\n",
    "        Estimate beta on mean-field Potts likelihood.\n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : array (height x width x number of classes)\n",
    "            Label field\n",
    "        lb : [(int, int)]\n",
    "            List of tuple of integers describing the lower and upper bound for\n",
    "            the smoothing parameter.\n",
    "        verbose : bool\n",
    "            Report final beta estimate.\n",
    "        Returns\n",
    "        -------\n",
    "        beta_hat : float\n",
    "            Estimated beta, or smoothing parameter, for given label field\n",
    "        \"\"\"\n",
    "        # Check if Z is the right shape\n",
    "        if len(Z.shape) == 2:\n",
    "\n",
    "            # Map to one-hot encoding\n",
    "            Z = self.one_hot(Z)\n",
    "\n",
    "        # Initial value\n",
    "        beta0 = np.array([10.0])\n",
    "\n",
    "        # Start optimization procedure\n",
    "        beta_hat = opt.minimize(fun=self.mean_field_Potts,\n",
    "                                x0=beta0,\n",
    "                                args=(Z),\n",
    "                                method='L-BFGS-B',\n",
    "                                # jac=self.mean_field_Potts_grad,\n",
    "                                bounds=lb,\n",
    "                                options={'disp': True}\n",
    "                                )\n",
    "\n",
    "        # Report value\n",
    "        if verbose:\n",
    "            print(beta_hat.x[0])\n",
    "\n",
    "        # Check value\n",
    "        if beta_hat.x[0] > 1e2:\n",
    "            print('Warning: beta_hat is very large.')\n",
    "\n",
    "        # Return\n",
    "        return beta_hat.x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(self, A):\n",
    "        \"\"\"\n",
    "        Map array to pages with binary encodings.\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : array (height by width)\n",
    "            2-dimensional array of integers\n",
    "        Returns\n",
    "        -------\n",
    "        B : array (height by width by number of unique integers in A)\n",
    "            3-dimensional array with each page as an indicator of value in A.\n",
    "        \"\"\"\n",
    "        # Unique values\n",
    "        labels = np.unique(A)\n",
    "\n",
    "        # Preallocate new array\n",
    "        B = np.zeros((*A.shape, len(labels)))\n",
    "\n",
    "        # Loop over unique values\n",
    "        for i, label in enumerate(labels):\n",
    "\n",
    "            B[:, :, i] = (A == label)\n",
    "\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neighbourhood(self, A, index, patch=True):\n",
    "        \"\"\"\n",
    "        Extract a neighbourhood of pixels around current pixel.\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : array\n",
    "            Array from which to extract the pixel's neighbourhood.\n",
    "        index : (int, int)\n",
    "            Row and column index of current pixel.\n",
    "        patch : bool\n",
    "            Whether to pair only with direct upper, lower and side pixels.\n",
    "        Returns\n",
    "        -------\n",
    "        delta_i : vector of neighbours of current pixel\n",
    "        \"\"\"\n",
    "        # Shape of array\n",
    "        H, W = A.shape\n",
    "\n",
    "        if not patch:\n",
    "\n",
    "            # Initialize neighbourhood list\n",
    "            delta_i = []\n",
    "\n",
    "            # Check for current pixel at top-left boundary\n",
    "            if np.all(index == (0, 0)):\n",
    "\n",
    "                delta_i.append(A[0, 1])\n",
    "                delta_i.append(A[1, 0])\n",
    "\n",
    "            # Check for current pixel at top boundary\n",
    "            elif (index[0] == 0) and (index[1] != 0 and index[1] != W-1):\n",
    "\n",
    "                delta_i.append(A[0, index[1]-1])\n",
    "                delta_i.append(A[0, index[1]+1])\n",
    "                delta_i.append(A[1, index[1]])\n",
    "\n",
    "            # Check for current pixel at top-right boundary\n",
    "            elif np.all(index == (0, W-1)):\n",
    "\n",
    "                delta_i.append(A[0, W-2])\n",
    "                delta_i.append(A[1, W-1])\n",
    "\n",
    "            # Check for current pixel at right boundary\n",
    "            elif (index[0] != 0 and index[0] != H-1) and (index[1] == H-1):\n",
    "\n",
    "                delta_i.append(A[index[0]-1, H-1])\n",
    "                delta_i.append(A[index[0]+1, H-1])\n",
    "                delta_i.append(A[index[0], H-2])\n",
    "\n",
    "            # Check for current pixel at bottom-right boundary\n",
    "            elif np.all(index == (H-1, W-1)):\n",
    "\n",
    "                delta_i.append(A[H-2, W-1])\n",
    "                delta_i.append(A[H-1, W-2])\n",
    "\n",
    "            # Check for current pixel at bottom boundary\n",
    "            elif (index[0] == H-1) and (index[1] != 0 and index[1] != W-1):\n",
    "\n",
    "                delta_i.append(A[H-1, index[1]-1])\n",
    "                delta_i.append(A[H-1, index[1]+1])\n",
    "                delta_i.append(A[H-2, index[1]])\n",
    "\n",
    "            # Check for current pixel at bottom-left boundary\n",
    "            elif np.all(index == (H-1, 0)):\n",
    "\n",
    "                delta_i.append(A[H-1, 1])\n",
    "                delta_i.append(A[H-2, 0])\n",
    "\n",
    "            # Check for current pixel at left boundary\n",
    "            elif (index[0] != 0 and index[0] != H-1) and (index[1] == 0):\n",
    "\n",
    "                delta_i.append(A[index[0]-1, 0])\n",
    "                delta_i.append(A[index[0]+1, 0])\n",
    "                delta_i.append(A[index[0], 1])\n",
    "\n",
    "            else:\n",
    "\n",
    "                delta_i.append(A[index[0]-1, index[1]])\n",
    "                delta_i.append(A[index[0], index[1]-1])\n",
    "                delta_i.append(A[index[0], index[1]+1])\n",
    "                delta_i.append(A[index[0]+1, index[1]])\n",
    "\n",
    "            # Return list, formatted to array\n",
    "            return np.array(delta_i)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Patch step size\n",
    "            vstep = int((self.neighbourhood_size[0] - 1) / 2)\n",
    "            hstep = int((self.neighbourhood_size[1] - 1) / 2)\n",
    "\n",
    "            # Pad image to allow slicing at the edges\n",
    "            A = np.pad(A, [vstep, hstep], mode='constant', constant_values=0)\n",
    "\n",
    "            # Define slices\n",
    "            vslice = slice(index[0]-vstep+vstep, index[0]+vstep+1+vstep)\n",
    "            hslice = slice(index[1]-hstep+hstep, index[1]+hstep+1+hstep)\n",
    "\n",
    "            # Initialize neighbourhood list\n",
    "            return A[vslice, hslice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función expectation_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Llama a las funciones:\n",
    "-neighbourhood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expectation_step(self, y, nu, theta, beta, neighbourhood_size=(1, 1)):\n",
    "        \"\"\"\n",
    "        Perform expectation step from variational-Bayes-EM.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array\n",
    "            Observed image.\n",
    "        nu : array\n",
    "            Array of variational parameters.\n",
    "        theta : array\n",
    "            Parameters of variational posterior of Potts model.\n",
    "        beta : float\n",
    "            Smoothing parameter.\n",
    "        neighbourhood_size : (int, int)\n",
    "            Size of the neighbourhood for mean-field.\n",
    "        Returns\n",
    "        -------\n",
    "        nu : array\n",
    "            Updated array of variational parameters.\n",
    "        \"\"\"\n",
    "        # Shape of variational parameter array\n",
    "        H, W, K = nu.shape\n",
    "\n",
    "        # Unpack tuple of hyperparameters\n",
    "        mu, la, ga, ks = theta\n",
    "\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                for k in range(K):\n",
    "\n",
    "                    # Compute expectation of log(tau_l) w.r.t. phi_l\n",
    "                    E_log_tau_l = sp.digamma(ga[k] / 2) - np.log(ks[k] / 2)\n",
    "\n",
    "                    # Compute expectation of tau_l w.r.t. phi_l\n",
    "                    E_tau_l = ga[k] / ks[k]\n",
    "\n",
    "                    # Compute expectation of log p(y_i|phi_l) w.r.t. phi_l\n",
    "                    E_log_py = (E_log_tau_l/2 -\n",
    "                                E_tau_l*(y[h, w] - mu[k])**2 / 2 -\n",
    "                                1 / (2*ks[k]))\n",
    "\n",
    "                    # Take sum over neighbourhood\n",
    "                    nu_di = self.neighbourhood(nu[:, :, k], (h, w))\n",
    "\n",
    "                    # Update variational parameter at current pixel\n",
    "                    nu[h, w, k] = np.exp(E_log_py + 2*beta*np.sum(nu_di))\n",
    "\n",
    "                # Normalize nu_i to 1\n",
    "                nu[h, w, :] = nu[h, w, :] / np.sum(nu[h, w, :])\n",
    "\n",
    "        return nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maximization_step(self, y, nu, theta, theta0):\n",
    "        \"\"\"\n",
    "        Perform maximization step from variational-Bayes-EM.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array\n",
    "            Observed image\n",
    "        nu : array\n",
    "            Variational parameters consisting of current segmentation.\n",
    "        theta : array\n",
    "            Hyperparameters for variational Potts-MRF.\n",
    "        theta0 : array\n",
    "            Initial values for hyperparameters.\n",
    "        Returns\n",
    "        -------\n",
    "        theta : array\n",
    "            Updated hyperparameters for variational Potts-MRF.\n",
    "        \"\"\"\n",
    "        # Check number of classes\n",
    "        K = nu.shape[2]\n",
    "\n",
    "        # Unpack tuples of hyperparameters\n",
    "        mu, la, ga, ks = theta\n",
    "        mu0, la0, ga0, ks0 = theta0\n",
    "\n",
    "        # Iterate over classes\n",
    "        for k in range(K):\n",
    "\n",
    "            # Update lambda\n",
    "            la[k] = la0[k] + np.sum(nu[:, :, k], axis=(0, 1))\n",
    "\n",
    "            # Update gamma\n",
    "            ga[k] = ga0[k] + np.sum(nu[:, :, k], axis=(0, 1))\n",
    "\n",
    "            # Update mu\n",
    "            mu[k] = (la0[k]*mu0[k] + np.sum(y*nu[:, :, k], axis=(0, 1)))/la[k]\n",
    "\n",
    "            # Update ksi\n",
    "            ks[k] = (ks0[k] + np.sum(y**2*nu[:, :, k], axis=(0, 1)) +\n",
    "                     la0[k]*mu0[k]**2 - la[k]*mu[k]**2)\n",
    "\n",
    "        return mu, la, ga, ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expectation_maximization(self, y, K, beta):\n",
    "        \"\"\"\n",
    "        Perform variational Bayes Expectation-Maximization.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array (height by width)\n",
    "            Image to be segmented.\n",
    "        K : int\n",
    "            Number of classes to segment image into.\n",
    "        beta : float\n",
    "            Smoothing parameter / granularity coefficient of Potts model.\n",
    "        Returns\n",
    "        -------\n",
    "        nu : array (height by width by number of classes)\n",
    "            Variational parameters of posterior for label image.\n",
    "        \"\"\"\n",
    "        # Get shape of image\n",
    "        H, W = y.shape\n",
    "\n",
    "        # Initialize hyperparameters\n",
    "        mu0 = np.zeros((K,))\n",
    "        la0 = np.zeros((K,))\n",
    "        ga0 = np.ones((K,)) / 2\n",
    "        ks0 = np.ones((K,)) / 2\n",
    "        theta0 = (mu0, la0, ga0, ks0)\n",
    "\n",
    "        # Copy hyperparameter array for updating\n",
    "        theta = np.copy(theta0)\n",
    "\n",
    "        # Initialize variational parameters array\n",
    "        nu = rnd.randn(H, W, K)\n",
    "\n",
    "        for r in range(self.num_iter):\n",
    "\n",
    "            # Report progress\n",
    "            print('At iteration ' + str(r+1) + '/' + str(self.num_iter))\n",
    "\n",
    "            # Expectation step\n",
    "            nu = self.expectation_step(y, nu, theta, beta)\n",
    "\n",
    "            # Expectation step\n",
    "            theta = self.maximization_step(y, nu, theta, theta0)\n",
    "\n",
    "        # Return segmentation along with estimated parameters\n",
    "        return nu, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama a las funciones:\n",
    "- maximum_likelihood_beta\n",
    "- expectation_maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment(self, y, K, Q=[], beta=1.0, output_params=False):\n",
    "        \"\"\"\n",
    "        Segment an image.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array\n",
    "            image to be segmented.\n",
    "        K : int\n",
    "            number of classes\n",
    "        Q : array\n",
    "            segmented image to copy smoothness from.\n",
    "        beta : float\n",
    "            Smoothing parameter.\n",
    "        output_params : bool\n",
    "            Whether to output the estimated hyperparameters.\n",
    "        Returns\n",
    "        -------\n",
    "        z : array\n",
    "            segmentation produced by the model.\n",
    "        \"\"\"\n",
    "        # Check for auxiliary segmentation\n",
    "        if np.any(Q):\n",
    "            beta = self.maximum_likelihood_beta(Q, verbose=True)\n",
    "\n",
    "        # Perform VB-EM for segmenting the image\n",
    "        nu, theta = self.expectation_maximization(y, K, beta)\n",
    "\n",
    "        # Return segmented image\n",
    "        if output_params:\n",
    "            return nu, theta\n",
    "        else:\n",
    "            return nu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
